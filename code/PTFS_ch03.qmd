---
title: "Practical Time Series Forecasting - Figures and Tables - Chapter 3"
format: html
editor: visual
execute:
  echo: true
  warning: false
---

Scripts adapted from [Practical Time Series Forecasting - Datasets & R Code](https://www.forecastingbook.com/resources/data-and-code)

## 3.1 Data Partitioning

### Figure 3.1

```{r}
#| message: false
#| warning: false
library(forecast)

amtrak_csv <- here::here("data", "Amtrak data.csv")
Amtrak.data <- read.csv(amtrak_csv)
ridership.ts <- ts(Amtrak.data$Ridership, start = c(1991, 1), end = c(2004, 3), freq = 12)

# Figure 3-1
plot(ridership.ts, ylim = c(1300, 2600),  ylab = "Ridership", xlab = "Time", bty = "l", xaxt = "n", xlim = c(1991,2006.25))
axis(1, at = seq(1991, 2006, 1), labels = format(seq(1991, 2006, 1), digits = 2))
lines(c(2004.25 - 3 , 2004.25 - 3), c(0, 3500))
lines(c(2004.25, 2004.25), c(0, 3500))
text(1996.25, 2500, "Training")
text(2002.75, 2500, "Validation")
text(2005.25, 2500, "Future")
arrows(2004 - 3,2450,1991.25,2450,code=3,length=0.1,lwd=1,angle=30)
arrows(2004.5 - 3,2450,2004,2450,code=3,length=0.1,lwd=1,angle=30)
arrows(2004.5,2450,2006,2450,code=3,length=0.1,lwd=1,angle=30)
```

Since the textbook omits the annotation in it's examples beyond Figure 3.1 for clarity, there is a mismatch between the code and the graphics output. We'll create a simple function t add the annotation to subsequent plots to keep the examples minimal. Here is Figure 3.1 reproduced with the annotation function.

```{r}
source(here::here('code', 'ptfs_functions.R'))
amtrak_ts_annotations
```

### Updated Figure 3.1

Updating the code using the `tidyverse` and `tidyverts` frameworks requires an updated annotation function:

```{r}
ridership_annotation
```

```{r}
#| warning: false
#| message: false
library(fpp3)
library(readxl)

ridership <- read_excel(here::here("data", "Amtrak data.xls"), 
    col_types = c("date", "numeric")) %>% 
  mutate(Month = yearmonth(Month)) %>% 
  as_tsibble(index = Month)

ridership_h <- ridership %>% 
  append_row(n = 21)

ridership_h %>% 
  autoplot(Ridership)  %>% 
  ridership_annotation()
```

### Figure 3.2

```{r}
stepsAhead <- 36
nTrain <- length(ridership.ts) - stepsAhead
train.ts <- window(ridership.ts, start = c(1991, 1), end = c(1991, nTrain))
valid.ts <- window(ridership.ts, start = c(1991, nTrain + 1), end = c(1991, nTrain + stepsAhead))
ridership.lm <-  tslm(train.ts ~ trend + I(trend^2))
ridership.lm.pred <- forecast(ridership.lm, h = stepsAhead, level = 0)

# Figure 3-2
plot(ridership.lm.pred, ylim = c(1300, 2600),  ylab = "Ridership", xlab = "Time", bty = "l", xaxt = "n", xlim = c(1991,2006.25), main = "", flty = 2)
axis(1, at = seq(1991, 2006, 1), labels = format(seq(1991, 2006, 1))) 
lines(ridership.lm$fitted, lwd = 2)
lines(valid.ts)

amtrak_ts_annotations(2500)


```

### Updated Figure 3.2

```{r}
library(fable) 

ridership_trn <- ridership_h %>% 
  filter_index("1991 Jan" ~ "2001 Mar")

ridership_val <- ridership_h %>% 
  filter_index("2001 Apr" ~ "2004 Mar")

# Fit the model
ridership_tslm <- ridership_trn %>% 
  model(tslm = TSLM(Ridership ~ trend() + I(trend()^2)))

# forecast the training and validation periods
ridership_fit <- ridership_tslm %>% 
  forecast(new_data = bind_rows(ridership_trn, ridership_val)) |> 
  mutate(is_training = Month <= yearmonth("2001 Mar"))

ridership_h %>% 
  autoplot(Ridership)  %>% 
  ridership_annotation() +
  # autolayer(ridership_fit, level = NULL)  
  # use ggplot functions to better match the original figure from the book
  geom_line(data = ridership_fit,
            aes(y = .mean, color = is_training, linetype = is_training))  +
  scale_color_manual(values = c("TRUE" = "black", "FALSE" = "skyblue")) +
  scale_linetype_manual(values = c("TRUE" = "solid", "FALSE" = "dashed")) +
  guides(color = "none", linetype = "none") 
```

## 3.3 Measuring Predictive Accuracy

### Table 3.1

```{r}
res <- round(valid.ts - ridership.lm.pred$mean, digits = 3)
table_3_1 <-cbind(ridership.lm.pred$mean, valid.ts, res) 
head(table_3_1, 3)
message('...')
tail(table_3_1, 1)

forecast::accuracy(ridership.lm.pred$mean, valid.ts)
```

### Updated Table 3.1

```{r}
ridership_fc <- ridership_tslm %>% 
  forecast(h = "3 years") 

bind_rows(ridership_fc |> head(3),
          ridership_fc |> tail(1))

# forecast accuracy for the validation period
ridership_fc |> 
  accuracy(ridership_val)
```

### Figure 3.3

```{r}
# Figure 3-3
plot(ridership.lm.pred$residuals, ylim = c(-400, 500),  ylab = "Residuals", xlab = "Time", bty = "l", xaxt = "n", xlim = c(1991,2006.25), main = "")
axis(1, at = seq(1991, 2006, 1), labels = format(seq(1991, 2006, 1)))
lines(valid.ts - ridership.lm.pred$mean, lwd = 1)

amtrak_ts_annotations(500)
```

### Figure 3.4

```{r}
# Figure 3-4
hist(ridership.lm.pred$residuals,  ylab = "Frequency", xlab = "Forecast Error", bty = "l", main = "")
```

### Updated Figures 3.3 & 3.4

Rather than reproduce the textbook figures, we'll use the `gg_tsresiduals()` function from the `fabletools` package to more easily create a common visualization of the residuals.

```{r}
ridership_tslm  |> 
  gg_tsresiduals()
```

### Figure 3.5

```{r}
nValid <- 36
nTrain <- length(ridership.ts) - nValid
train.ts <- window(ridership.ts, start = c(1991, 1), end = c(1991, nTrain))
valid.ts <- window(ridership.ts, start = c(1991, nTrain + 1), end = c(1991, nTrain + nValid))
ridership.lm <-  tslm(train.ts ~ trend + I(trend^2))
ridership.lm.pred <- forecast(ridership.lm, h = nValid, level = 95)

plot(ridership.lm.pred, ylim = c(1300, 2600),  ylab = "Ridership", xlab = "Time", bty = "l", xaxt = "n", xlim = c(1991,2006.25), main = "", flty = 2)
axis(1, at = seq(1991, 2006, 1), labels = format(seq(1991, 2006, 1))) 
lines(ridership.lm$fitted, lwd = 2)
lines(valid.ts)

amtrak_ts_annotations(2500)
```

### Updated Figure 3.5

```{r}
ridership_fc |> 
  autoplot(ridership_h) |> 
  ridership_annotation()
```

## 3.5 Advanced Data Partitioning: Roll-Forward Validation

### Figure 3.6

```{r}
tumblr_csv <- here::here('data', 'Tumblr.csv')
tumblr.data <- read.csv(tumblr_csv)
people.ts <- ts(tumblr.data$People.Worldwide) / 1000000

# Run three exponential smoothing models: AAN, MMN, and MMdN.
# MMN stands for Multiplicative error, Multiplicative trend, and No seasonality. MMdN stands for Multiplicative error, Multiplicative damped trend, and No seasonality.
people.ets.AAN <- ets(people.ts, model = "AAN")
people.ets.MMN <- ets(people.ts, model = "MMN", damped = FALSE)
people.ets.MMdN <- ets(people.ts, model = "MMN", damped = TRUE)

# Create their prediction "cones" for 115 months into the future (Jun 2013 to Dec 2022).
people.ets.AAN.pred <- forecast(people.ets.AAN, h = 115, level = c(0.2, 0.4, 0.6, 0.8))
people.ets.MMN.pred <- forecast(people.ets.MMN, h = 115, level = c(0.2, 0.4, 0.6, 0.8))
people.ets.MMdN.pred <- forecast(people.ets.MMdN, h = 115, level = c(0.2, 0.4, 0.6, 0.8))

# Compare the three models' "forecast cones" visually.

par(mfrow = c(1, 3)) # This command sets the plot window to show 1 row of 3 plots.
plot(people.ets.AAN.pred, xlab = "Month", ylab = "People (in millions)", ylim = c(0, 1000))
plot(people.ets.MMN.pred, xlab = "Month", ylab="People (in millions)", ylim = c(0, 1000))
plot(people.ets.MMdN.pred, xlab = "Month", ylab="People (in millions)", ylim = c(0, 1000))

# Examine the lower and upper limits of the MMN model's prediction cones.
# people.ets.MMN.pred$lower %>% head()
# people.ets.MMN.pred$upper %>% tail()
```

### Updated Figure 3.6

NOTE:

This updated code uncovers a few issues with the `fable` package at the time of this run. 1. The `forecast.ETS()` function is slower than the `forecast.ets()` function for Multiplicative models. This chunck takes about 200 seconds on a MacBook Pro. 2. The level argument is not working (is ignored) for the `forecast.ETS()` function. 3. autoplot doesn't display the prediction intervals if they exceed the plot y-axis limits.

```{r}
#| cache: true

tumblr_people <- tumblr.data |> 
  transmute(id = row_number(),
         people = People.Worldwide / 1e6) |> 
  as_tsibble(index = id)

#fit 3 ETS models to the data [AAN, MMN, MMdN]
tumblr_ets <- tumblr_people |> 
  model(ets_ann = ETS(people ~ error('A') + trend('A') + season('N')),
        ets_mmn = ETS(people ~ error('M') + trend('M') + season('N')),
        ets_mmdn = ETS(people ~ error('M') + trend('Md') + season('N')))

#forecast 115 months into the future
library(tictoc)
tic()
tumblr_fc <- tumblr_ets |> 
  forecast(h = 115, level = c(0.2, 0.4, 0.6, 0.8))
tcapture <- toc()

autoplot(tumblr_fc, tumblr_people) +
    facet_grid(. ~ .model) +
  ylim(-100, 1000) +
  guides(colour = 'none', fill = 'none') +
  scale_color_manual(values = rep('blue', 3)) +
  scale_fill_manual(values = rep('blue', 3))
```

### Figure 3.7

```{r}
fixed.nValid <- 36
fixed.nTrain <- length(ridership.ts) - fixed.nValid
train.ts <- window(ridership.ts, start = c(1991, 1), end = c(1991, fixed.nTrain))
valid.ts <- window(ridership.ts, start = c(1991, fixed.nTrain + 1), end = c(1991, fixed.nTrain + fixed.nValid))
naive.fixed <- naive(train.ts, h = fixed.nValid)
naive.roll <- ts(Amtrak.data$Ridership[fixed.nTrain:(fixed.nTrain + fixed.nValid - 1)], start = c(1991, fixed.nTrain + 1), end = c(1991, fixed.nTrain + fixed.nValid), freq = 12)

# Figure 3-6
plot(train.ts, ylim = c(1300, 2600),  ylab = "Ridership", xlab = "Time", bty = "l", xaxt = "n", xlim = c(1991,2006.25), main = "")
axis(1, at = seq(1991, 2006, 1), labels = format(seq(1991, 2006, 1)))
lines(naive.fixed$mean, lwd = 2, col = "blue", lty = 2)
lines(naive.roll, lwd = 2, col = "purple", lty = 2)
lines(valid.ts)

amtrak_ts_annotations()
```

### Updated Figure 3.7

```{r}
# create a rolling forecast with the naive method
ridership_roll_naive <- ridership |> 
  filter_index('2001 Mar' ~ '2004 Mar') |>  # only need the last point for naive forecast
  stretch_tsibble(.init = 1, .step = 1) |> 
  filter(.id != max(.id)) |>
  model(naive = NAIVE(Ridership)) |> 
  augment()
```

```{r}
# create a rolling forecast with the naive method
ridership_naive_roll <- ridership |> 
  filter_index('2001 Mar' ~ '2004 Mar') |>  # only need the last point for naive forecast
  model(naive = NAIVE(Ridership)) |> 
  augment()

# create a rolling forecast with the fixed method
ridership_naive_fixed <- ridership_trn |> 
  model(naive = NAIVE(Ridership)) 

ridership_naive_fixed_fc <- ridership_naive_fixed |> 
  forecast(h = 36)

autoplot(ridership_naive_fixed_fc, level = NULL)

autoplot(ridership_h) |>  
  ridership_annotation() +
  autolayer(ridership_naive_roll, .vars = .fitted, color = 'blue', linetype = 'dashed')  +
  autolayer(ridership_naive_fixed_fc, level = NULL, color = 'purple', linetype = 'dashed') 
  

```

### Table 3.3

```{r}
suppressMessages(library(tidyverse))

fixed.nValid <- 36
fixed.nTrain <- length(ridership.ts) - fixed.nValid
mae <- rep(0,fixed.nValid)
rmse <- rep(0,fixed.nValid)
mape <- rep(0,fixed.nValid)
for(i in 1:36) {
  stepsAhead <- i
  error <- rep(0, fixed.nValid - stepsAhead + 1)
  percent.error <- rep(0, fixed.nValid - stepsAhead + 1)
  for(j in fixed.nTrain:(fixed.nTrain + fixed.nValid - stepsAhead)) {
    train.ts <- window(ridership.ts, start = c(1991, 1), end = c(1991, j))
    valid.ts <- window(ridership.ts, start = c(1991, j + stepsAhead), end = c(1991, j + stepsAhead))
    naive.pred <- naive(train.ts, h = stepsAhead)
    error[j - fixed.nTrain + 1] <- valid.ts - naive.pred$mean[stepsAhead]
    percent.error[j - fixed.nTrain + 1] <- error[j - fixed.nTrain + 1] / valid.ts
  }
  mae[i] <- mean(abs(error))
  rmse[i] <- sqrt(mean(error^2))
  mape[i] <- mean(abs(percent.error))
}
# mean(mae)
# mean(rmse)
# mean(mape)

train.ts <- window(ridership.ts, start = c(1991, 1), end = c(1991, fixed.nTrain))
valid.ts <- window(ridership.ts, start = c(1991, fixed.nTrain + 1), end = c(1991, fixed.nTrain + fixed.nValid))
naive.pred <- naive(train.ts, h = fixed.nValid)
snaive.pred <- snaive(train.ts, h = fixed.nValid)
# accuracy(naive.pred, valid.ts)
# accuracy(snaive.pred, valid.ts)
naive_acc <- forecast::accuracy(naive.pred, valid.ts)

method_desc <- sprintf('Rolling Forward %d-months ahead', 1:length(mae))
table_3_3 <- tibble(Method = method_desc, MAE = mae, RMSE = rmse, MAPE = mape) %>% bind_rows(tibble(Method = 'Roll Forward Overall',
                                                                                                    MAE = mean(mae),
                                                                                                    RMSE = mean(rmse),
                                                                                                    MAPE = mean(mape)),
                                                                                             tibble(Method = 'Fixed Partition Overall',
                                                                                                    MAE = naive_acc['Test set', 'MAE'],
                                                                                                    RMSE = naive_acc['Test set', 'RMSE'],
                                                                                                    MAPE = naive_acc['Test set', 'MAPE']))


table_3_3_abbr <- bind_rows(
  table_3_3[1:3, ],
  tibble(Method = '...'),
  table_3_3[36:38,]
)

table_3_3_abbr
```

### Table 3.4

```{r}
suppressMessages(library(lubridate))
table_3_4 <- bind_rows(tibble(
  Period = naive.pred %>% as.data.frame %>% row.names.data.frame(),
  Actual = valid.ts,
  `Naive Forecast` = naive.pred$mean,
  `Seasonal Naive Forecast` = snaive.pred$mean
))
table_3_4_disp <- bind_rows(
  table_3_4[1:3, ],
  tibble(Period = '...'),
  table_3_4[nrow(table_3_4), ]
)
table_3_4_disp
```

### Table 3.5

```{r}
snaive.pred <- snaive(train.ts, h = fixed.nValid)
snaive_acc <- forecast::accuracy(snaive.pred, valid.ts)

table_3_5 <-  bind_rows(
  tibble(Method = 'Fixed Partition Overall',
                     MAE = naive_acc['Test set', 'MAE'],
                     RMSE = naive_acc['Test set', 'RMSE'],
                     MAPE = naive_acc['Test set', 'MAPE']),
  tibble(Method = 'Fixed Partition Overall',
                     MAE = snaive_acc['Test set', 'MAE'],
                     RMSE = snaive_acc['Test set', 'RMSE'],
                     MAPE = snaive_acc['Test set', 'MAPE']))
table_3_5
```

### Table 3.5

```{r}
fixed.nValid <- 36
fixed.nTrain <- length(ridership.ts) - fixed.nValid
stepsAhead <- 1
error.naive <- rep(0, fixed.nValid - stepsAhead + 1)
percent.error.naive <- rep(0, fixed.nValid - stepsAhead + 1)
error.snaive <- rep(0, fixed.nValid - stepsAhead + 1)
percent.error.snaive <- rep(0, fixed.nValid - stepsAhead + 1)
for(j in fixed.nTrain:(fixed.nTrain + fixed.nValid - stepsAhead)) {
  train.ts <- window(ridership.ts, start = c(1991, 1), end = c(1991, j))
  valid.ts <- window(ridership.ts, start = c(1991, j + stepsAhead), end = c(1991, j + stepsAhead))
  naive.pred <- naive(train.ts, h = stepsAhead)
  snaive.pred <- snaive(train.ts, h = stepsAhead)
  error.naive[j - fixed.nTrain + 1] <- valid.ts - naive.pred$mean[stepsAhead]
  percent.error.naive[j - fixed.nTrain + 1] <- error.naive[j - fixed.nTrain + 1] / valid.ts
  error.snaive[j - fixed.nTrain + 1] <- valid.ts - snaive.pred$mean[stepsAhead]
  percent.error.snaive[j - fixed.nTrain + 1] <- error.snaive[j - fixed.nTrain + 1] / valid.ts
}

table_3_6 <- tibble(
  Method = c('Naive Forecast', 'Seasonal Naive Forecast'),
  MAE = c(mean(abs(error.naive)), mean(abs(error.snaive))),
  RMSE = c(sqrt(mean(error.naive^2)), sqrt(mean(error.snaive^2))),
  MAPE = c(mean(abs(percent.error.naive)), mean(abs(percent.error.snaive)))
)
table_3_6
```
